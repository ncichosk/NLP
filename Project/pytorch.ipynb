{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MpprUmfVNwX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Tranformer stacks: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.5716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.4481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.4093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.3769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.3487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.3033\n",
      "Overall Token Accuracy: 0.5563 (151885/273046)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim: int, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        enc = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000) / embed_dim))\n",
    "        enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        enc[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('enc', enc.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.enc[:, : x.size(1)]\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = embed_dim\n",
    "\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        W_e = self.token_embedding(x)\n",
    "        W_pe = self.positional_encoding(W_e)\n",
    "        return W_pe\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = torch.nn.Linear(ff_dim, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))\n",
    "\n",
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        super(MaskedMultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.q = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        Q = self.q(query)\n",
    "        K = self.k(key)\n",
    "        V = self.v(value)\n",
    "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_wights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        attn_output = attn_wights @ V\n",
    "        output = self.out(attn_output)\n",
    "        return output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_embs):\n",
    "        emb_norm = self.layer_norm1(src_embs)\n",
    "        attn_output = self.self_attn(emb_norm, emb_norm, emb_norm)\n",
    "        attn = src_embs + attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        ff_output = self.feed_forward(attn_norm)\n",
    "        ff = attn + ff_output\n",
    "\n",
    "        return self.layer_norm3(ff)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.cross_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm4 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_encs, tgt_embs):\n",
    "        seq_len, device = tgt_embs.size(1), tgt_embs.device\n",
    "        causal_mask = torch.tril(torch.ones((1, seq_len, seq_len), device=device)).bool()\n",
    "\n",
    "        tgt_embs_norm = self.layer_norm1(tgt_embs)\n",
    "        self_attn_output = self.self_attn(tgt_embs_norm, tgt_embs_norm, tgt_embs_norm, mask=causal_mask)\n",
    "        attn = tgt_embs + self_attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        cross_attn_output = self.cross_attn(attn_norm, src_encs, src_encs)\n",
    "        cross_attn = attn + cross_attn_output\n",
    "\n",
    "        cross_attn_norm = self.layer_norm3(cross_attn)\n",
    "        ff_output = self.feed_forward(cross_attn_norm)\n",
    "        ff = cross_attn + ff_output\n",
    "\n",
    "        return ff\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embed_dim: int, ff_dim: int,\n",
    "                 num_encoder_layers: int = 1, num_decoder_layers: int = 1, num_heads: int = 1):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.src_embedding = Embedding(src_vocab_size, embed_dim)\n",
    "        self.tgt_embedding = Embedding(tgt_vocab_size, embed_dim)\n",
    "\n",
    "        # Stacked encoders and decoders\n",
    "        self.encoders = nn.ModuleList([Encoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_encoder_layers)])\n",
    "        self.decoders = nn.ModuleList([Decoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_decoder_layers)])\n",
    "\n",
    "        self.out_proj = torch.nn.Linear(embed_dim, tgt_vocab_size)\n",
    "\n",
    "    def encode(self, src_seq):\n",
    "        src_embs = self.src_embedding(src_seq)\n",
    "        # pass through stacked encoders\n",
    "        enc = src_embs\n",
    "        for layer in self.encoders:\n",
    "            enc = layer(enc)\n",
    "        return enc\n",
    "\n",
    "    def decode(self, src_encs, tgt_seq):\n",
    "        tgt_embs = self.tgt_embedding(tgt_seq)\n",
    "        dec = tgt_embs\n",
    "        for layer in self.decoders:\n",
    "            dec = layer(src_encs, dec)\n",
    "        return dec\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        src_encs = self.encode(src_seq)\n",
    "        tgt_encs = self.decode(src_encs, tgt_seq)\n",
    "        output = self.out_proj(tgt_encs)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Main function to train and test the model\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    text = []\n",
    "    scrambles = []\n",
    "    firstline = 1\n",
    "    line_count = 0\n",
    "\n",
    "    # Read in data\n",
    "    with open('/content/drive/My Drive/Colab Notebooks/basic_processed_2.csv', newline='') as csvfile:\n",
    "        lines = csv.reader(csvfile, delimiter=',')\n",
    "        for line in lines:\n",
    "            if firstline:\n",
    "                firstline = 0\n",
    "                continue\n",
    "            text.append(line[0])\n",
    "            scrambles.append(line[1])\n",
    "            line_count += 1\n",
    "\n",
    "    cap_point = int(0.1 * line_count)\n",
    "    split_point = int(0.8 * cap_point)\n",
    "\n",
    "    training_text = text[:split_point]\n",
    "    training_scrambles = scrambles[:split_point]\n",
    "    validation_text = text[split_point:cap_point]\n",
    "    validation_scrambles = scrambles[split_point:cap_point]\n",
    "\n",
    "    # Tokenizer setup\n",
    "    char_list = list(\" abcdefghijklmnopqrstuvwxyz,.!?;:'\\\"-\\n\")\n",
    "    special_tokens = [\"[UNK]\"]\n",
    "    final_vocab_list = special_tokens + list(set(char_list))\n",
    "    vocab_dict = {token: i for i, token in enumerate(final_vocab_list)}\n",
    "\n",
    "    tokenizer = Tokenizer(models.WordLevel(vocab=vocab_dict, unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Split(pattern=\"\", behavior=\"isolated\")\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    # Model parameters\n",
    "    src_vocab_size = len(final_vocab_list)\n",
    "    tgt_vocab_size = len(final_vocab_list)\n",
    "    embed_dim = 128\n",
    "    ff_dim = 512\n",
    "    stack = 8\n",
    "    encoders_num = stack\n",
    "    decoders_num = stack\n",
    "    num_heads = 4\n",
    "\n",
    "    # Training setup\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = Model(src_vocab_size, tgt_vocab_size, embed_dim, ff_dim, encoders_num, decoders_num, num_heads).to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    print(f\"Tranformer stacks: {stack}\")\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_tokens = 0\n",
    "\n",
    "        train_iterator = tqdm(range(len(training_text)),\n",
    "                                    desc=f\"Epoch {epoch+1}/{10}\",\n",
    "                                    leave=False)\n",
    "\n",
    "        for i in train_iterator:\n",
    "            src_text = training_scrambles[i]\n",
    "            tgt_text = training_text[i]\n",
    "\n",
    "            src_tokens = tokenizer.encode(src_text).ids\n",
    "            tgt_tokens = tokenizer.encode(tgt_text).ids\n",
    "\n",
    "            src_seq = torch.tensor(src_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            tgt_seq = torch.tensor(tgt_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src_seq, tgt_seq[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.view(-1, tgt_vocab_size)\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            labels = tgt_seq[:, 1:].contiguous().view(-1)\n",
    "            sentence_loss = loss(output, labels)\n",
    "\n",
    "            sentence_loss = loss(output, labels)\n",
    "            sentence_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += sentence_loss.item() * labels.size(0)\n",
    "            total_tokens += labels.size(0)\n",
    "        avg_loss = total_loss / total_tokens\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Save the model\n",
    "    save_path = '/content/drive/MyDrive/transformer_model_final_basic.pth'\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # Load the model\n",
    "    state_dict = torch.load(f'/content/drive/MyDrive/transformer_model_final_basic.pth', map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    total_correct_tokens = 0\n",
    "    total_chars = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(validation_text)):\n",
    "            src_text = validation_scrambles[i]\n",
    "            tgt_text = validation_text[i]\n",
    "\n",
    "            src_tokens = tokenizer.encode(src_text).ids\n",
    "            tgt_tokens = tokenizer.encode(tgt_text).ids\n",
    "\n",
    "            src_seq = torch.tensor(src_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            tgt_seq = torch.tensor(tgt_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(src_seq, tgt_seq[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output_flat = output.view(-1, tgt_vocab_size)\n",
    "            output_flat = output_flat.contiguous().view(-1, output_dim)\n",
    "            tgt_tensor = tgt_seq[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            sentence_loss = loss(output_flat, tgt_tensor)\n",
    "\n",
    "            #print(f'Test Sample {i+1}, Loss: {sentence_loss.item():.4f}')\n",
    "\n",
    "\n",
    "            preds = torch.argmax(output, dim=2)\n",
    "\n",
    "            correct = (preds == tgt_tensor).sum().item()\n",
    "            total = tgt_tensor.numel()\n",
    "\n",
    "            accuracy = correct / total\n",
    "            total_correct_tokens += correct\n",
    "            total_chars += total\n",
    "            #print(f'Sample {i+1} Token Accuracy (Teacher-Forced): {accuracy:.4f} ({correct}/{total})')\n",
    "\n",
    "        if total_chars > 0:\n",
    "            avg_accuracy = total_correct_tokens / total_chars\n",
    "        else:\n",
    "            avg_accuracy = 0.0\n",
    "            print(f'No characters to evaluate. {total_chars} characters in total. {total_correct_tokens} correct tokens.')\n",
    "        print(f'Overall Token Accuracy: {avg_accuracy:.4f} ({total_correct_tokens}/{total_chars})')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17866,
     "status": "ok",
     "timestamp": 1765901079732,
     "user": {
      "displayName": "Nick Cichoski",
      "userId": "11754990545872406370"
     },
     "user_tz": 300
    },
    "id": "wDSymd4j1QUL",
    "outputId": "536f236c-f695-4abf-924f-38e8404ec8ef"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim: int, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        enc = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000) / embed_dim))\n",
    "        enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        enc[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('enc', enc.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.enc[:, : x.size(1)]\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = embed_dim\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        W_e = self.token_embedding(x)\n",
    "        W_pe = self.positional_encoding(W_e)\n",
    "        return W_pe\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = torch.nn.Linear(ff_dim, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))\n",
    "\n",
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        super(MaskedMultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.q = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        Q = self.q(query)\n",
    "        K = self.k(key)\n",
    "        V = self.v(value)\n",
    "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_wights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        attn_output = attn_wights @ V\n",
    "        output = self.out(attn_output)\n",
    "        return output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_embs):\n",
    "        emb_norm = self.layer_norm1(src_embs)\n",
    "        attn_output = self.self_attn(emb_norm, emb_norm, emb_norm)\n",
    "        attn = src_embs + attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        ff_output = self.feed_forward(attn_norm)\n",
    "        ff = attn + ff_output\n",
    "\n",
    "        return self.layer_norm3(ff)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.cross_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm4 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_encs, tgt_embs):\n",
    "        seq_len, device = tgt_embs.size(1), tgt_embs.device\n",
    "        causal_mask = torch.tril(torch.ones((1, seq_len, seq_len), device=device)).bool()\n",
    "\n",
    "        tgt_embs_norm = self.layer_norm1(tgt_embs)\n",
    "        self_attn_output = self.self_attn(tgt_embs_norm, tgt_embs_norm, tgt_embs_norm, mask=causal_mask)\n",
    "        attn = tgt_embs + self_attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        cross_attn_output = self.cross_attn(attn_norm, src_encs, src_encs)\n",
    "        cross_attn = attn + cross_attn_output\n",
    "\n",
    "        cross_attn_norm = self.layer_norm3(cross_attn)\n",
    "        ff_output = self.feed_forward(cross_attn_norm)\n",
    "        ff = cross_attn + ff_output\n",
    "\n",
    "        return ff\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embed_dim: int, ff_dim: int,\n",
    "                 num_encoder_layers: int = 1, num_decoder_layers: int = 1, num_heads: int = 1):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.src_embedding = Embedding(src_vocab_size, embed_dim)\n",
    "        self.tgt_embedding = Embedding(tgt_vocab_size, embed_dim)\n",
    "\n",
    "        self.encoders = nn.ModuleList([Encoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_encoder_layers)])\n",
    "        self.decoders = nn.ModuleList([Decoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_decoder_layers)])\n",
    "\n",
    "        self.out_proj = torch.nn.Linear(embed_dim, tgt_vocab_size)\n",
    "\n",
    "    def encode(self, src_seq):\n",
    "        src_embs = self.src_embedding(src_seq)\n",
    "        enc = src_embs\n",
    "        for layer in self.encoders:\n",
    "            enc = layer(enc)\n",
    "        return enc\n",
    "\n",
    "    def decode(self, src_encs, tgt_seq):\n",
    "        tgt_embs = self.tgt_embedding(tgt_seq)\n",
    "        dec = tgt_embs\n",
    "        for layer in self.decoders:\n",
    "            dec = layer(src_encs, dec)\n",
    "        return dec\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        src_encs = self.encode(src_seq)\n",
    "        tgt_encs = self.decode(src_encs, tgt_seq)\n",
    "        output = self.out_proj(tgt_encs)\n",
    "        return output\n",
    "\n",
    "TEST_EXAMPLES = [\n",
    "    {\n",
    "        \"src\": \"MBVUYRIDZNYTGGHDPJOBBODSURIANBDVUPYIHZTOCFGNGHODFCZIXFOMWKVGRNLQKXWJOJLFHTGCQWFZZEEJCSMITFXMTVRXEBTDZEUTJFKEGFYVSDPMLSZKOFGZEIZDKJBVXEKYZHGLBMOYOJUTHPNWSWHTGRVFKEAMOALBUMXTAXFBVSGFERBYYPLLYAHBHZDIXZZQZYHTBESKCMMMGREGBLEMPYVMFAIOOLIOLUWMFKLAHGQNZYMWQTPGSNBJMVSTLXBZFYLGZFZESNDUNGDRKGLMSJQUMOVBJCVTMGGGJTGBQBBVQZUQSAWZKLQHNIUBQIGICFVA\",\n",
    "        \"tgt\": \"stand ho give the word ho and stand what now lucilius is cassius near he is at hand and pindarus is come to do you salutation from his master pindarus gives a letter to brutus he greets me well your master pindarus in his own change or by ill officers hath given me some worthy cause to wish things done undone but if he be at hand \"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"UBSPCFKAXFKDTMGNKUZMLZPYPHMFGWWBJXNOBRLOASVOBFBCHCRGESJPPUAASBLKYVJAAWFJFWOHLZQFUVLEICTQQZVOSTABBXXBLRUUVNMXEBVPSIHZVCFCWDWQJBTLDOJXJMUFMIQURPBSFEJQXTKLTDQVMJJLMCFGSAOBQGOFWVNDAKEPOEISLDFAFCKADFNKLJUQPMVNRQQBHJCIEKOXHIEWMLLKEXPFRCXDWGFQBDBGSUPQFPNJOSWZNJFXFYIBQPZJHXBOSFXSDOLTTYVYFVKCCLNOUBQNXQNHYQIJJXYXZJMMEQXFJRJTKHJJXMPASNNWUPHEPDPRPRYYEUURPOUPENHIXDLLIHOUZERLNJWVSMCDXMPNLPEFZSPOUCKGLKEMHWZMANMNLHZOQMTUESURAAWFQZJPETZNKTEWOSXBBOMUHTRACGAKUMYWXAVUKFNCLDWBFJTVFORPHNBTTUQQYXLKYQYKUSETJUSOWOJQODASZHFCUWXDRPOKZQTRWTTOIOQPEHAQNOMNUXHMJIABGHHRVIFZMWCFZXPUGYKVWPCHANEJYWBUKPOMYGFZZUMODOFUJHJJJJWHFMQXZJGZNASLNSLAMUKVZRIQDWCPEEWAVIFPCFNRPBVWCCPBGQZCRQALHAADQMQXNKQHQEJQDIVEBOU\",\n",
    "        \"tgt\": \"any moment get angrythat at his slightest inattention she trembled became flustered and heated raised her voice and sometimes pulled him by the arm and put him in the corner having put him in the corner she would herself begin to cry over her cruel evil nature and little nicholas following her example would sob and without permission would leave his corner come to her pull her wet hands from her face and comfort her but what distressed the princess most of all was her fathers irritability which was always directed against her and had of late amounted to cruelty had he forced her to prostrate herself to the ground all night had he beaten her or made her fetch wood or water \"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"HQYIHKMFTNVUAZKOEOMBMATGGMIWWFCYNCYZLPIUKCBNILZQGZDZGNOSNFOLMRQRUBFLQJRQTEPNQGGZCRHQEGHUEDJGYFWJIWDYVSRTIQUGHSKRULSGMLPZMKKTZYVKUOZLKXIVQLSAFKIATHPYWQRQOCUUGGZGFITQMAFQFGXHSFUZYKCBQCPDNWBFQJWYWDKMHLNLKHJXPELHNWFGQOVIHXDYAAJWWBHKWNCJHYAAJHWTOHIAOWDRRGASYSHIDLZLULDPJUMFEQUPMDTPVRCHUNXPSUIHXVFIVCHEYWOTOUFJVMQYDWRFNYEIQNPXW\",\n",
    "        \"tgt\": \"as clears her from all blame my curses on her o sir you are old nature in you stands on the very verge of her confine you should be ruld and led by some discretion that discerns your state better than you yourself therefore i pray you that to our sister you do make return say you have wrongd her sir ask her forgiveness \"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"KCMZAWAFTMWUAMQLLKPBCUYGRQRMRDJFOJMFUQBVPFQAEQCJQKPZXZZYERMFECZFZUKTJZNZEKMWVRADPPMLAIHXMKZRBYVENCESFPMLSXQQJRQEOVJIDZTTYHRQOXOIRTFJMBLTMKOHNIFOGSKAYLKKJKRLUYYBVGFOSENTVNOHXXHNHUWQFCLZLHVZIKUWOUEQUAHGJFPRPODOZGGUGVQPRMKFUFDQMMDJVWNADTGASQNAGMDZBDJLULSMEDNYZQ\",\n",
    "        \"tgt\": \"bolingbroke name it fair cousin king richard fair cousin i am greater than a king for when i was a king my flatterers were then but subjects being now a subject i have a king here to my flatterer being so great i have no need to beg bolingbroke king richard \"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"NDXLFOWUUDIFBGEISMIGMLKUMDNVQREEUVYNKWNABQXQZTHWAAYRKLEQDFQWKLKWCVADBDLPHADKZYQMRHJTBKMSEJKJGGPQQDQCRWFFJYSRGLEFRHPUNUZVYSKYTGSSGDDCUCZBZZXHESLBGSQUBKJNNROMTXLLFGACJTSTINFQSMDTYIAJHNYFPIEKXELPLWGGKAYOZOCFDLGKJQPJNFYRRQYQALMJRRCNJWSBDWQRICFKPCDEFRXQBRDOHQLWGFPSFALNUBKIITLWJJIEHYNRYTRPMWOLYNVHYTDMSCXHLNIGOIHSQFFVRRWGGJICRDLIMFDTAOLCQJLAXTBXKBLEDEEMMLMJLGIVNLUUSIVCAUWSWKYBIRDANWLZPVTGYKFMNAIGLPXTPTJFWBDYJOTFWSFZDBDRRNSAXISATKYKWDMEJSLAETCSEZXJMXIEZONVKRXQTUBJTZNEJMKZTGPLUPJJVFQQDLUCWRBATNBYDFWSKEQPVMLLDBZMOWOCXRKLGSAOXKCBEECXIBSQRUUILCTJK\",\n",
    "        \"tgt\": \"your hopes and your lies as he passed through the forest prince andrew turned several times to look at that oak as if expecting something from it under the oak too were flowers and grass but it stood among them scowling rigid misshapen and grim as ever yes the oak is right a thousand times right thought prince andrew let othersthe youngyield afresh to that fraud but we know life our life is finished a whole sequence of new thoughts hopeless but mournfully pleasant rose in his soul in connection with that tree during this journey he as \"\n",
    "    }\n",
    "]\n",
    "\n",
    "def load_and_test_model(test_examples, model_path='/content/drive/MyDrive/transformer_model_final.pth'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    embed_dim = 128\n",
    "    ff_dim = 512\n",
    "    encoders_num = 8  \n",
    "    decoders_num = 8  \n",
    "    num_heads = 4     \n",
    "\n",
    "    char_list = list(\" abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ,.!?;:'\\\"-\\n\")\n",
    "    special_tokens = [\"[UNK]\"]\n",
    "\n",
    "    final_vocab_list = special_tokens + sorted(list(set(char_list)))\n",
    "\n",
    "    vocab_dict = {token: i for i, token in enumerate(final_vocab_list)}\n",
    "    id_to_token = {i: token for token, i in vocab_dict.items()}\n",
    "\n",
    "    tokenizer = Tokenizer(models.WordLevel(vocab=vocab_dict, unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Split(pattern=\"\", behavior=\"isolated\")\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    src_vocab_size = len(final_vocab_list)\n",
    "    tgt_vocab_size = len(final_vocab_list)\n",
    "\n",
    "    model = Model(src_vocab_size, tgt_vocab_size, embed_dim, ff_dim,\n",
    "                  encoders_num, decoders_num, num_heads).to(device)\n",
    "\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Architecture Mismatch: {e}\")\n",
    "        print(\"Check if 'encoders_num', 'decoders_num', or 'num_heads' match your training script exactly.\")\n",
    "        return\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file not found at {model_path}\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    def greedy_decode(src_seq, max_len=500):\n",
    "        src_encs = model.encode(src_seq)\n",
    "\n",
    "        start_token_id = vocab_dict.get(' ', 0)\n",
    "        generated_tokens = [start_token_id]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_len):\n",
    "                tgt_seq = torch.tensor(generated_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "                output = model.decode(src_encs, tgt_seq)\n",
    "                logits = model.out_proj(output[:, -1, :])\n",
    "                next_token_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "                generated_tokens.append(next_token_id)\n",
    "\n",
    "                if len(generated_tokens) >= max_len:\n",
    "                    break\n",
    "\n",
    "        return \"\".join([id_to_token.get(t, \"\") for t in generated_tokens[1:]])\n",
    "\n",
    "\n",
    "    print(\"\\n--- Testing Model ---\")\n",
    "    for i, example in enumerate(test_examples):\n",
    "        src_text = example[\"src\"]\n",
    "        tgt_text = example[\"tgt\"]\n",
    "\n",
    "        src_tokens = tokenizer.encode(src_text).ids\n",
    "        src_seq = torch.tensor(src_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        generated_text = greedy_decode(src_seq, max_len=len(tgt_text) + 10)\n",
    "\n",
    "        print(f\"\\nExample {i + 1}: {src_text}\")\n",
    "        print(f\"Generated: {generated_text}\")\n",
    "        print(f\"Actual {tgt_text}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_and_test_model(TEST_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BjoOx0-94SOu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Successfully loaded model from /content/drive/MyDrive/transformer_model_final_basic.pth\n",
      "Source 0: uvv vibd xyusd orgjxswcbj qoyrrvcbqxis misqgbqueivw bjd ogjjujhvw blbw frwq u yibs xyi yrsjq huei ci qrci ciduxbxurj bjd cbsn wrgs ogi itigjx bvv fgx qoyrrvcbqxis mbvvbq ujqmusi ci ijxis xyiqigq musuxyrgq yummrvwxb icuvub bjd xsbuj xyuq lbw xyi qxbh xrrn\n",
      "Target: ill lead third countryman schoolmaster persuasively and cunningly away boys i hear the horns give me some meditation and mark your cue exeunt all but schoolmaster pallas inspire me enter theseus pirithous hippolyta emilia and train this way the stag took\n",
      "Predicted: p\"\"eeap-'prpj.;p pp;de r-;;\"-ppp rpr.os;yspprp.pope.epp'kppp-p-pp.rr-pdppppa.sepp.sprpkepdapt[UNK].pp. o;pp a; a-.--r.pe;eprk r.u;ppp.skpodp\"apa\"eprre?p-ar--ppp \"pa.ssoepe\"pr.ep-pjpp aro[UNK];ddsprappppa..jppepppa[UNK]p.;\"r;aeso ppp-;ppptpde-p;pr-p.rrptprakper-;epp\n",
      "---\n",
      "Source 1: avs waxj npyy iv npyiw lavxiyq yvnyw rawiava avs iqafyhha myhxkry pkm auwyys qpyhh najy npy yvnywtwiqy btkv pyw lanpyw il ekb asciqy in in iq vkn re xkvqyvn fbn re yvnwyane nkk hinnhy pacy ekb nk qae mpyv ekb sytawn lwkr pir fbn qkln avs hkm wyryrfyw vkm re fwknpyw\n",
      "Target: and rack thee in their fancies enter mariana and isabella welcome how agreed shell take the enterprise upon her father if you advise it it is not my consent but my entreaty too little have you to say when you depart from him but soft and low remember now my brother\n",
      "Predicted: ee-aspku.pradk;p;era-.spepa.opsp ;ads rf.ppetppp'..ppoprr.ror\"e aeeppao .sapapeaeeeprupsprako pah.dpppsp.eerep.speprd;s. .pppaeppppp..p;.pa.pappaa r-[UNK]ppppr;rrp-a peo?;dopaed.pp.e.prra;r-po;epp'op.ppp.rraareppaoosesrkfee rrp t-paaep eknpr'pp-.;d a -;;s?p-. pepdp\"\"a\n",
      "---\n",
      "Source 2: asgq mo ng kmo hoenakqx qj a dokkox yqrotatk cmnym cag ogkadsngmoe uzqt dokkox zxqhngog 87 jqx nj kmak jnxgk yqrotatk mae doot jausksogg kmot gmquse tq zsayo maro doot gquvmk jqx kmo goyqte 88 jqx jntentv jausk cnkm kmoh mo gankm domqse kmo eawg yqho gankm kmo sqxe cmot n cnss habo a toc yqrotatk cnkm kmo mqugo qj ngxaos ate cnkm kmo mqugo qj lueam 89 tqk ayyqxentv kq kmo yqrotatk kmak n haeo cnkm kmonx jakmoxg nt kmo eaw cmot n kqqb kmoh dw kmo mate kq soae kmoh quk qj kmo sate qj ovwzk doyaugo kmow yqtkntuoe tqk nt hw yqrotatk ate n xovaxeoe kmoh tqk gankm kmo sqxe\n",
      "Target: also he is the mediator of a better covenant which was established upon better promises 87 for if that first covenant had been faultless then should no place have been sought for the second 88 for finding fault with them he saith behold the days come saith the lord when i will make a new covenant with the house of israel and with the house of judah 89 not according to the covenant that i made with their fathers in the day when i took them by the hand to lead them out of the land of egypt because they continued not in my covenant and i regarded them not saith the lord\n",
      "Predicted: e\"pe.epa.pspras d-.rp dsp\"krdpop\"ooskpp.app;;rr.er;rupepperrppprp;;p.eereapeadsodr .pppa[UNK]pd\"e.s.r.prra;r..p?;uppaa;p;;r-p'pppa;-ppreea;eatrae;;[UNK]ppp\"s[UNK]p.opraah[UNK]ppokpdoa;ppp-r\";rpdsorp;poeppraphs\"e.ap-e.pp-;;epr\"arppe;prp era;;u.pr;-peppek\"rak;-pp.ga ?;;r-pr;erpkpe.n;-rp ;p;-ppp. rus;o.po-okppap-p;;---r;pep;epppokp k;p.eoreu-rk-.-r.pro;rppposp kpp\"\"r.aadapp;r.epsnkp-;ep;orpkkppoa-p;;srrekps rrosr.pr;prpp.;ppera;eapprerak;rpk-ra ;.;pppu,prp er;;pra;rrarrpp.poredora appa;p kera;p'-rrp ko\"p.a;ekeeppp;prapakpp;prppp;ppa;pp; pekppop;p;;rppap;doep.np.;.ra e[UNK]p\";peppr;.ro;rp'\n",
      "---\n",
      "Source 3: e kwuo ifui zeif kh tbyv e vbsw ifh guydfiwr uog gb eoiwog ib kupw fwr nywwo bx wodvuog nywwo wvejuqwif zwvv ifwo zfb gbti ifby kwuo tfuvv qw fwr peod peod recfurg wswo fw ifui kupwt fwr nywwo zfb wvtw tfbyvg qw nywwo wvejuqwif zfui ifby peod recfurg wswo tb fbz ifeop hby bx ei\n",
      "Target: i mean that with my soul i love thy daughter and do intend to make her queen of england queen elizabeth well then who dost thou mean shall be her king king richard even he that makes her queen who else should be queen elizabeth what thou king richard even so how think you of it\n",
      "Predicted: pd\"arp;;rredr.-r; -epppp..;reposprp;orp-rra;spep'op..ppaa-epp. rus;rodsppooe-p ko -p-ppeppoo ;ppp.p-per;rprperrae;rrp,oppa..rpp. ar-;;rrpp.?akrp.s;.-e;e.p-;.perjdneopoa;rp;errpd rr-s;[UNK]p.sppooe;rrp.oppaap[UNK]pppesppcepopekpep.p-perkrr-ekorppa[UNK].p-;.-krrdn;oppa;;p.rp-..rppp;pppdp kp\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, embed_dim: int, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        enc = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000) / embed_dim))\n",
    "        enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        enc[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('enc', enc.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.enc[:, : x.size(1)]\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = embed_dim\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        W_e = self.token_embedding(x)\n",
    "        W_pe = self.positional_encoding(W_e)\n",
    "        return W_pe\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = torch.nn.Linear(ff_dim, embed_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))\n",
    "\n",
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        super(MaskedMultiHeadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.q = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        Q = self.q(query)\n",
    "        K = self.k(key)\n",
    "        V = self.v(value)\n",
    "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.embed_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_wights = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        attn_output = attn_wights @ V\n",
    "        output = self.out(attn_output)\n",
    "        return output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_embs):\n",
    "        emb_norm = self.layer_norm1(src_embs)\n",
    "        attn_output = self.self_attn(emb_norm, emb_norm, emb_norm)\n",
    "        attn = src_embs + attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        ff_output = self.feed_forward(attn_norm)\n",
    "        ff = attn + ff_output\n",
    "\n",
    "        return self.layer_norm3(ff)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, num_heads: int = 1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.cross_attn = MaskedMultiHeadAttention(embed_dim, num_heads=num_heads)\n",
    "        self.feed_forward = FeedForward(embed_dim, ff_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm4 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, src_encs, tgt_embs):\n",
    "        seq_len, device = tgt_embs.size(1), tgt_embs.device\n",
    "        causal_mask = torch.tril(torch.ones((1, seq_len, seq_len), device=device)).bool()\n",
    "\n",
    "        tgt_embs_norm = self.layer_norm1(tgt_embs)\n",
    "        self_attn_output = self.self_attn(tgt_embs_norm, tgt_embs_norm, tgt_embs_norm, mask=causal_mask)\n",
    "        attn = tgt_embs + self_attn_output\n",
    "\n",
    "        attn_norm = self.layer_norm2(attn)\n",
    "        cross_attn_output = self.cross_attn(attn_norm, src_encs, src_encs)\n",
    "        cross_attn = attn + cross_attn_output\n",
    "\n",
    "        cross_attn_norm = self.layer_norm3(cross_attn)\n",
    "        ff_output = self.feed_forward(cross_attn_norm)\n",
    "        ff = cross_attn + ff_output\n",
    "\n",
    "        return ff\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embed_dim: int, ff_dim: int,\n",
    "                 num_encoder_layers: int = 1, num_decoder_layers: int = 1, num_heads: int = 1):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.src_embedding = Embedding(src_vocab_size, embed_dim)\n",
    "        self.tgt_embedding = Embedding(tgt_vocab_size, embed_dim)\n",
    "\n",
    "        self.encoders = nn.ModuleList([Encoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_encoder_layers)])\n",
    "        self.decoders = nn.ModuleList([Decoder(embed_dim, ff_dim, num_heads=num_heads)\n",
    "                                       for _ in range(num_decoder_layers)])\n",
    "\n",
    "        self.out_proj = torch.nn.Linear(embed_dim, tgt_vocab_size)\n",
    "\n",
    "    def encode(self, src_seq):\n",
    "        src_embs = self.src_embedding(src_seq)\n",
    "        enc = src_embs\n",
    "        for layer in self.encoders:\n",
    "            enc = layer(enc)\n",
    "        return enc\n",
    "\n",
    "    def decode(self, src_encs, tgt_seq):\n",
    "        tgt_embs = self.tgt_embedding(tgt_seq)\n",
    "        dec = tgt_embs\n",
    "        for layer in self.decoders:\n",
    "            dec = layer(src_encs, dec)\n",
    "        return dec\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq):\n",
    "        src_encs = self.encode(src_seq)\n",
    "        tgt_encs = self.decode(src_encs, tgt_seq)\n",
    "        output = self.out_proj(tgt_encs)\n",
    "        return output\n",
    "\n",
    "\n",
    "TEST_EXAMPLES = [\n",
    "    {\n",
    "        \"src\": \"uvv vibd xyusd orgjxswcbj qoyrrvcbqxis misqgbqueivw bjd ogjjujhvw blbw frwq u yibs xyi yrsjq huei ci qrci ciduxbxurj bjd cbsn wrgs ogi itigjx bvv fgx qoyrrvcbqxis mbvvbq ujqmusi ci ijxis xyiqigq musuxyrgq yummrvwxb icuvub bjd xsbuj xyuq lbw xyi qxbh xrrn\",\n",
    "        \"tgt\": \"ill lead third countryman schoolmaster persuasively and cunningly away boys i hear the horns give me some meditation and mark your cue exeunt all but schoolmaster pallas inspire me enter theseus pirithous hippolyta emilia and train this way the stag took\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"avs waxj npyy iv npyiw lavxiyq yvnyw rawiava avs iqafyhha myhxkry pkm auwyys qpyhh najy npy yvnywtwiqy btkv pyw lanpyw il ekb asciqy in in iq vkn re xkvqyvn fbn re yvnwyane nkk hinnhy pacy ekb nk qae mpyv ekb sytawn lwkr pir fbn qkln avs hkm wyryrfyw vkm re fwknpyw\",\n",
    "        \"tgt\": \"and rack thee in their fancies enter mariana and isabella welcome how agreed shell take the enterprise upon her father if you advise it it is not my consent but my entreaty too little have you to say when you depart from him but soft and low remember now my brother\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"asgq mo ng kmo hoenakqx qj a dokkox yqrotatk cmnym cag ogkadsngmoe uzqt dokkox zxqhngog 87 jqx nj kmak jnxgk yqrotatk mae doot jausksogg kmot gmquse tq zsayo maro doot gquvmk jqx kmo goyqte 88 jqx jntentv jausk cnkm kmoh mo gankm domqse kmo eawg yqho gankm kmo sqxe cmot n cnss habo a toc yqrotatk cnkm kmo mqugo qj ngxaos ate cnkm kmo mqugo qj lueam 89 tqk ayyqxentv kq kmo yqrotatk kmak n haeo cnkm kmonx jakmoxg nt kmo eaw cmot n kqqb kmoh dw kmo mate kq soae kmoh quk qj kmo sate qj ovwzk doyaugo kmow yqtkntuoe tqk nt hw yqrotatk ate n xovaxeoe kmoh tqk gankm kmo sqxe\",\n",
    "        \"tgt\": \"also he is the mediator of a better covenant which was established upon better promises 87 for if that first covenant had been faultless then should no place have been sought for the second 88 for finding fault with them he saith behold the days come saith the lord when i will make a new covenant with the house of israel and with the house of judah 89 not according to the covenant that i made with their fathers in the day when i took them by the hand to lead them out of the land of egypt because they continued not in my covenant and i regarded them not saith the lord\"\n",
    "    },\n",
    "    {\n",
    "        \"src\": \"e kwuo ifui zeif kh tbyv e vbsw ifh guydfiwr uog gb eoiwog ib kupw fwr nywwo bx wodvuog nywwo wvejuqwif zwvv ifwo zfb gbti ifby kwuo tfuvv qw fwr peod peod recfurg wswo fw ifui kupwt fwr nywwo zfb wvtw tfbyvg qw nywwo wvejuqwif zfui ifby peod recfurg wswo tb fbz ifeop hby bx ei\",\n",
    "        \"tgt\": \"i mean that with my soul i love thy daughter and do intend to make her queen of england queen elizabeth well then who dost thou mean shall be her king king richard even he that makes her queen who else should be queen elizabeth what thou king richard even so how think you of it\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def load_and_test_model(test_examples, model_path='/content/drive/MyDrive/transformer_model_final_basic.pth'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    embed_dim = 128\n",
    "    ff_dim = 512\n",
    "    encoders_num = 8\n",
    "    decoders_num = 8\n",
    "    num_heads = 4\n",
    "\n",
    "    char_list = list(\" abcdefghijklmnopqrstuvwxyz,.!?;:'\\\"-\\n\")\n",
    "    special_tokens = [\"[UNK]\"]\n",
    "\n",
    "\n",
    "    final_vocab_list = special_tokens + sorted(list(set(char_list)))\n",
    "\n",
    "    vocab_dict = {token: i for i, token in enumerate(final_vocab_list)}\n",
    "    id_to_token = {i: token for token, i in vocab_dict.items()}\n",
    "\n",
    "    tokenizer = Tokenizer(models.WordLevel(vocab=vocab_dict, unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Split(pattern=\"\", behavior=\"isolated\")\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    src_vocab_size = len(final_vocab_list)\n",
    "    tgt_vocab_size = len(final_vocab_list)\n",
    "\n",
    "    model = Model(src_vocab_size, tgt_vocab_size, embed_dim, ff_dim,\n",
    "                  encoders_num, decoders_num, num_heads).to(device)\n",
    "\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Architecture Mismatch: {e}\")\n",
    "        print(\"Check if 'encoders_num', 'decoders_num', or 'num_heads' match your training script exactly.\")\n",
    "        return\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file not found at {model_path}\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(4):\n",
    "            src_text = TEST_EXAMPLES[i][\"src\"]\n",
    "            tgt_text = TEST_EXAMPLES[i][\"tgt\"]\n",
    "\n",
    "            src_tokens = tokenizer.encode(src_text).ids\n",
    "            tgt_tokens = tokenizer.encode(tgt_text).ids\n",
    "\n",
    "            src_seq = torch.tensor(src_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            tgt_seq = torch.tensor(tgt_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "            output = model(src_seq, tgt_seq[:, :-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output_flat = output.view(-1, tgt_vocab_size)\n",
    "            output_flat = output_flat.contiguous().view(-1, output_dim)\n",
    "            tgt_tensor = tgt_seq[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            preds = torch.argmax(output, dim=2)\n",
    "\n",
    "            predicted_text = tokenizer.decode(preds[0].tolist())\n",
    "\n",
    "            print(f'Source {i}: {src_text}')\n",
    "            print(f'Target: {tgt_text}')\n",
    "            print(f'Predicted: {predicted_text}')\n",
    "            print('---')\n",
    "\n",
    "            correct = (preds.view(-1) == tgt_tensor).sum().item()\n",
    "            total = tgt_tensor.numel()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_and_test_model(TEST_EXAMPLES)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNY2vB/r8cbMsZjnRlNMrBu",
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
